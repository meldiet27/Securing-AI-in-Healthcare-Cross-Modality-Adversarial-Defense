{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17fdbc62",
   "metadata": {},
   "source": [
    "# Securing Machine Learning Models: Attacks and Defenses\n",
    "\n",
    "The notebook investigates methods to attack machine learning models as well as defense strategies against such attacks. \n",
    "The analysis draws from knowledge acquired throughout lectures about SVMs and neural networks and ensemble learning and decision trees and evaluation metrics and additional topics.\n",
    "\n",
    "**Goals:**\n",
    "- Demonstrate adversarial attack techniques (FGSM)\n",
    "- Evaluate model robustness\n",
    "- Use concepts such as PCA and ensemble methods for discussion\n",
    "- Propose and implement defenses like adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchattacks import FGSM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef528b37",
   "metadata": {},
   "source": [
    "##  Data Loading and Preprocessing\n",
    "The experiment uses a MNIST, a handwritten digit dataset (28x28 grayscale images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ba830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transform\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Download datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aebe526",
   "metadata": {},
   "source": [
    "##  CNN Model Architecture\n",
    "Following principles from Lecture 8 (Neural Networks), a convolutional neural network (CNN) is defined.\n",
    "This model will be vulnerable to adversarial inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8267b6",
   "metadata": {},
   "source": [
    "## Training and Evaluation Functions\n",
    "Training follows supervised learning using CrossEntropyLoss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c22eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, loader, optimizer, adversarial=False, attack=None):\n",
    "    model.train()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        if adversarial and attack:\n",
    "            data = attack(data, target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(model, device, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a22625",
   "metadata": {},
   "source": [
    "##  Experiment: FGSM Attack vs Adversarial Training\n",
    "This code demonstrates how adversarial examples reduce accuracy â€” and how adversarial training helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f258f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Standard training\n",
    "for epoch in range(3):\n",
    "    train(model, device, train_loader, optimizer)\n",
    "\n",
    "clean_acc = test(model, device, test_loader)\n",
    "print(f\"Accuracy on clean test set: {clean_acc:.2f}%\")\n",
    "\n",
    "# FGSM attack\n",
    "attack = FGSM(model, eps=0.3)\n",
    "adv_acc = test(model, device, test_loader)\n",
    "print(f\"Accuracy under FGSM attack: {adv_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2088799d",
   "metadata": {},
   "source": [
    "##  Defense: Adversarial Training\n",
    "This code uses FGSM examples during training to increase robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c12fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial training\n",
    "model_adv = CNN().to(device)\n",
    "optimizer_adv = optim.Adam(model_adv.parameters(), lr=0.001)\n",
    "attack_adv = FGSM(model_adv, eps=0.3)\n",
    "\n",
    "for epoch in range(3):\n",
    "    train(model_adv, device, train_loader, optimizer_adv, adversarial=True, attack=attack_adv)\n",
    "\n",
    "adv_train_acc = test(model_adv, device, test_loader)\n",
    "print(f\"Accuracy after adversarial training: {adv_train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8696a",
   "metadata": {},
   "source": [
    "## Key findings\n",
    "- Clean model accuracy dropped after attack\n",
    "- Adversarial training improves defense\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
